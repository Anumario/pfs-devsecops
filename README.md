# üõ°Ô∏è Pipeline DevSecOps Self-Healing assist√© par IA (Llama 3)

Ce projet impl√©mente une cha√Æne CI/CD automatis√©e capable de d√©tecter des vuln√©rabilit√©s critiques 
dans une application Flask et de proposer des correctifs automatiques via un LLM local.

## üöÄ Architecture
- **Target :** Application Flask (vuln√©rabilit√©s SQLi, Secrets, Root User).
- **Watcher :** GitHub Actions + Trivy (Scan de s√©curit√©).
- **Brain :** Ollama + Llama 3 (Analyse et rem√©diation).
- **Fixer :** Script Python (GitPython) cr√©ant des Pull Requests automatiques.

## üõ†Ô∏è Installation
1. **Pr√©requis :** Ubuntu 22.04, Docker, Python 3.10+, Ollama.
2. **Installer Ollama :** `curl -fsSL https://ollama.com/install.sh | sh`
3. **T√©l√©charger le mod√®le :** `ollama pull llama3`
4. **Configuration Python :**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r app/requirements.txt
   pip install GitPython requests
